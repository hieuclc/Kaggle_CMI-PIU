{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Data loading & Processing\n",
    "\n",
    "**Refer to sections 1.1 and 1.2 for our analysis of the dataset, which provides the foundation for the techniques and methods, including imputation and feature engineering, discussed in section 1.3.**\n",
    "\n",
    "**In this section, we will outline the process of creating a dataset that we believe is clean and high-quality for training the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering helper function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_of_statistics(data, time = None):\n",
    "    try:\n",
    "        #Handle empty dataframe\n",
    "        if (data.empty or len(data.columns) == 0 or data is None):\n",
    "            return {}\n",
    "        \n",
    "        if len(data.columns) == 0:\n",
    "            return {}\n",
    "        \n",
    "        #Aggreate statistics for the dictionary\n",
    "        stats_summary = data.agg(['mean', 'median', 'max', 'std']).to_dict()\n",
    "        \n",
    "        flattened_stats = {}\n",
    "        for col, stats in stats_summary.items():\n",
    "            for stat_name, value in stats.items():\n",
    "                key = f\"{stat_name}_{col}\"\n",
    "                if (time is not None):\n",
    "                    key = f\"{stat_name}_{col}_{time}\"\n",
    "                flattened_stats[key] = value\n",
    "        \n",
    "        return flattened_stats\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "#Feature engineering\n",
    "\n",
    "def compute_time_features(data, day_start_hour=6, day_end_hour=18, expected_diff=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute and add time-related features to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'time_of_day' in nanosecond and 'relative_date_PCIAT'.\n",
    "    - day_start_hour (int): Hour to start the day period. Default is 8.\n",
    "    - day_end_hour (int): Hour to end the day period. Default is 21.\n",
    "    - expected_diff (int): Expected time difference between steps in seconds. Default is 5.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #From nanosecond to hour in a day\n",
    "    data['time_of_day_hours'] = data['time_of_day'] / 1e9 / 3600\n",
    "    data['day_time'] = data['relative_date_PCIAT'] + data['time_of_day_hours'] / 24\n",
    "    \n",
    "    #Categorize the day and night based on time data\n",
    "    \n",
    "    data['day_period'] = np.where(\n",
    "        (data['time_of_day_hours'] >= day_start_hour) &\n",
    "        (data['time_of_day_hours'] < day_end_hour),\n",
    "        'day', 'night'\n",
    "    )\n",
    "    \n",
    "    #Time difference beween steps\n",
    "    #As the description, the time_of_day should represent the start of a 5s window over which the data was sampled\n",
    "    #Calculate the time difference between each step\n",
    "    data['time_diff'] = (data['day_time'].diff() * 86400).round(0) # seconds in a day\n",
    "    data['measurement_after_gap'] = data['time_diff'] > expected_diff\n",
    "    \n",
    "def no_motion_periods(worn_data):\n",
    "    \"\"\"\n",
    "    Find periods of no motion and give analytical insights in the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'time_of_day' and 'relative_date_PCIAT'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with new features: \n",
    "    + total duration of no motion periods per day\n",
    "    + the number of no motion periods per day.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Calculate no motion periods\n",
    "    no_motion = worn_data['enmo'] == 0\n",
    "    motion_group = (\n",
    "        (no_motion != no_motion.shift()) |\n",
    "        (worn_data['measurement_after_gap'])\n",
    "    ).cumsum()\n",
    "\n",
    "    no_motion_periods = worn_data[no_motion].groupby(\n",
    "        motion_group\n",
    "    )['day_time'].agg(['min', 'max'])\n",
    "\n",
    "    no_motion_periods['duration_sec'] = (\n",
    "        (no_motion_periods['max'] - no_motion_periods['min']) * 86400\n",
    "    ).round(0).astype(int)\n",
    "    \n",
    "    no_motion_periods['duration_sec'] += 5\n",
    "    no_motion_periods['day'] = no_motion_periods['min'].astype(int)\n",
    "    \n",
    "    # Calculate daily statistics on no motion periods\n",
    "    daily_stats = no_motion_periods.groupby(no_motion_periods['day']) \\\n",
    "        .agg(no_motion_duration=('duration_sec', 'sum'),\n",
    "            no_motion_count=('duration_sec', 'size'))\n",
    "    \n",
    "    #Aggreate statistics for the dictionary\n",
    "    return dictionary_of_statistics(daily_stats)\n",
    "\n",
    "def circadian_rhythm_analysis(worn_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Make features capturing the variation in activity across the 24-hour cycle, \n",
    "    separately for day and night times (or wakefulness and sleep periods).\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'time_of_day_hours', 'day_period' and 'relative_date_PCIAT'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: 2 DataFrame, corresponding to day and night times,  with new features capturing the circadian rhythm of the wearer,\n",
    "    + Standard deviation across hourly means per day\n",
    "    + Peak hour of activity per day\n",
    "    + Entropy of activity distribution per day\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if (worn_data.empty or worn_data is None):\n",
    "            return {}\n",
    "    \n",
    "        hourly_activity = worn_data.groupby(\n",
    "            [worn_data['relative_date_PCIAT'].astype(int),\n",
    "            worn_data['time_of_day_hours'].astype(int),\n",
    "            worn_data['day_period']]\n",
    "        )['enmo'].agg(['mean', 'max'])\n",
    "\n",
    "        features = hourly_activity['mean'].groupby(\n",
    "            ['relative_date_PCIAT', 'day_period']\n",
    "        ).agg(\n",
    "            std_across_hours='std',\n",
    "            peak_hour=lambda x: x.idxmax()[1],\n",
    "            entropy=lambda x: -(x / x.sum() * np.log(x / x.sum() + 1e-9)).sum()\n",
    "        )\n",
    "        \n",
    "        # Safely extract day/night features\n",
    "        try:\n",
    "            day_features = features.xs('day', level='day_period')\n",
    "        except:\n",
    "            day_features = pd.DataFrame()\n",
    "            \n",
    "        try:    \n",
    "            night_features = features.xs('night', level='day_period')\n",
    "        except:\n",
    "            night_features = pd.DataFrame()\n",
    "\n",
    "        return dictionary_of_statistics(day_features, time=\"day\") | dictionary_of_statistics(night_features, time='night')  \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def physical_activity_analysis(worn_data):\n",
    "        \n",
    "    \"\"\"\n",
    "    Analyze the Moderate to Vigorous Physical Activity (MVPA) based on a threshold of ENMO values, \n",
    "    and calculate the duration of the detected MVPA activity bouts\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'enmo', 'time_diff' and 'day_time'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with new features capturing the physical activity level of the wearer,\n",
    "    including:\n",
    "    + Total duration of MVPA per day\n",
    "    + Number of MVPA periods per day\n",
    "    \"\"\"\n",
    "    # In order to classify physical activity as MVPA, we only retained activities that lasted at least 1 minute and met the criteria for the 100 mg (= 0.1g) threshold\n",
    "    if worn_data is None or worn_data.empty:\n",
    "        return {}\n",
    "    \n",
    "    mvpa_threshold = 0.1\n",
    "    merge_gap = 60\n",
    "    \n",
    "    def merge_mvpa_groups(df, allowed_gap=60, merge_gap=60):\n",
    "        last_mvpa_time = df['day_time'].where(df['is_mvpa']).ffill().shift()\n",
    "        \n",
    "        mvpa_time_diff = (\n",
    "            (df['day_time'] - last_mvpa_time) * 86400\n",
    "        ).round(0)\n",
    "        \n",
    "        mvpa_group = (\n",
    "            (df['is_mvpa'] != df['is_mvpa'].shift()) |\n",
    "            (df['time_diff'] >= allowed_gap)\n",
    "        ).cumsum()\n",
    "        \n",
    "        is_mvpa_start = (\n",
    "            (mvpa_group != mvpa_group.shift()) &\n",
    "            df['is_mvpa']\n",
    "        )\n",
    "        \n",
    "        group_increment = is_mvpa_start & (\n",
    "            (mvpa_time_diff >= merge_gap) | last_mvpa_time.isnull()\n",
    "        )\n",
    "        \n",
    "        merged_group = group_increment.cumsum()\n",
    "        merged_group.loc[~df['is_mvpa']] = np.nan\n",
    "        \n",
    "        return merged_group\n",
    "    \n",
    "    worn_data['is_mvpa'] = worn_data['enmo'] > mvpa_threshold\n",
    "    worn_data['mvpa_merged_group'] = merge_mvpa_groups(worn_data)\n",
    "\n",
    "    mvpa_periods = worn_data[\n",
    "        worn_data['is_mvpa']\n",
    "    ].groupby('mvpa_merged_group')['day_time'].agg(['min', 'max'])\n",
    "\n",
    "    mvpa_periods['duration_sec'] = (\n",
    "        mvpa_periods['max'] - mvpa_periods['min']\n",
    "    ) * 86400  # days to seconds\n",
    "\n",
    "    mvpa_periods = mvpa_periods[mvpa_periods['duration_sec'] >= 60]\n",
    "    mvpa_periods['duration_min'] = mvpa_periods['duration_sec'] / 60\n",
    "    \n",
    "    mvpa_periods['day'] = mvpa_periods['min'].astype(int)\n",
    "\n",
    "    daily_stats = mvpa_periods.groupby(mvpa_periods['day']) \\\n",
    "        .agg(mvpa_total_duration=('duration_sec', 'sum'),\n",
    "            mvpa_count_periods=('duration_sec', 'size'))\n",
    "        \n",
    "    return dictionary_of_statistics(daily_stats)\n",
    "    \n",
    "def activity_transition_analysis(worn_data):\n",
    "        \n",
    "    \"\"\"\n",
    "    The analysis to look at transitions between low, moderate and vigorous activity. To smooth out sudden, \n",
    "    short bursts of different activities, we filter out segments with a duration below a 1 minute threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'enmo', 'time_diff' and 'day_time'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with new features capturing the activity transitions of the wearer,\n",
    "    + Total duration of different of activity per day\n",
    "    + Number of different activity periods per day\n",
    "    \"\"\"\n",
    "    mvpa_threshold = 0.1\n",
    "    vig_threshold = 0.5\n",
    "    worn_data['activity_type'] = pd.cut(\n",
    "        worn_data['enmo'],\n",
    "        bins=[-np.inf, mvpa_threshold, vig_threshold, np.inf],\n",
    "        labels=['low', 'moderate', 'vigorous']\n",
    "    )\n",
    "    activity_group = (\n",
    "        (worn_data['activity_type'] != worn_data['activity_type'].shift()) |\n",
    "        (worn_data['measurement_after_gap'])\n",
    "    ).cumsum()\n",
    "    \n",
    "    activity_periods = worn_data.groupby(activity_group).agg(\n",
    "        min=('day_time', 'min'),\n",
    "        max=('day_time', 'max'),\n",
    "        activity_type=('activity_type', 'first')\n",
    "    )\n",
    "    activity_periods['duration_sec'] = (\n",
    "        activity_periods['max'] - activity_periods['min']\n",
    "    ) * 86400 + 5 \n",
    "\n",
    "    activity_periods = activity_periods[activity_periods['duration_sec'] >= 60]\n",
    "    activity_periods['duration_min'] = activity_periods['duration_sec'] / 60\n",
    "    \n",
    "    activity_periods['day'] = activity_periods['min'].astype(int)\n",
    "    activity_periods['transition_num'] = (\n",
    "        activity_periods.groupby('day')['activity_type']\n",
    "        .apply(lambda x: (x != x.shift()).cumsum())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    low_activity = activity_periods[activity_periods['activity_type'] == 'low'].groupby('day').agg(\n",
    "        low_act_total_duration=('duration_sec', 'sum'),\n",
    "        low_act_count_periods=('duration_sec', 'size')\n",
    "    )\n",
    "    \n",
    "    moderate_activity = activity_periods[activity_periods['activity_type'] == 'moderate'].groupby('day').agg(\n",
    "            moderate_act_total_duration=('duration_sec', 'sum'),\n",
    "            moderate_act_count_periods=('duration_sec', 'size')\n",
    "    )\n",
    "\n",
    "        \n",
    "    daily_transitions = activity_periods.groupby('day').agg(\n",
    "        count_transitions=('transition_num', 'max')\n",
    "    )\n",
    "    \n",
    "    return dictionary_of_statistics(low_activity) | dictionary_of_statistics(moderate_activity) | dictionary_of_statistics(daily_transitions)\n",
    "\n",
    "def activity_light_exposure(worn_data):\n",
    "        \n",
    "    \"\"\"\n",
    "    Analyze the correlation between light exposure and physical activity level.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'light' and 'enmo'.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The correlation between light exposure and physical activity level.\n",
    "    \"\"\"\n",
    "    correlation_light_enmo = worn_data[['light', 'enmo']].corr().iloc[0, 1]\n",
    "    return {'correlation_light_enmo': correlation_light_enmo}\n",
    "\n",
    "def process_file(file_path, participant_id):\n",
    "    try:\n",
    "        data = pd.read_parquet(file_path)\n",
    "        \n",
    "        if data.empty:\n",
    "            return {'id': participant_id}\n",
    "        \n",
    "        required_columns = ['time_of_day', 'relative_date_PCIAT', 'enmo', 'non-wear_flag', 'light']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            return {'id': participant_id}\n",
    "\n",
    "        # Compute time features\n",
    "        compute_time_features(data)\n",
    "            \n",
    "        # Calculate the percentage of non-worn time\n",
    "        non_wear_percentage = (data['non-wear_flag'].sum() / len(data)) * 100\n",
    "        \n",
    "        # Filter out the worn data\n",
    "        worn_data = data[data['non-wear_flag'] == 0]\n",
    "        \n",
    "        if (worn_data.empty):\n",
    "            return {'id': participant_id}\n",
    "        \n",
    "        # recalculate time difference between rows and measurement_after_gap flag in the worn data\n",
    "        expected_diff = 5\n",
    "        worn_data['time_diff'] = (worn_data['day_time'].diff() * 86400).round(0)\n",
    "        worn_data['measurement_after_gap'] = worn_data['time_diff'] > expected_diff\n",
    "\n",
    "        # Compute no motion periods\n",
    "        no_motion_stats = no_motion_periods(worn_data)\n",
    "        # Circadian rhythm analysis\n",
    "        circadian_rhythm_stats = circadian_rhythm_analysis(worn_data)\n",
    "        # Physical activity analysis\n",
    "        physical_activity_stats = physical_activity_analysis(worn_data)\n",
    "        # Activity transition analysis\n",
    "        activity_transition_stats = activity_transition_analysis(worn_data)\n",
    "        # Compute activity light correlation\n",
    "        activity_light_stats = activity_light_exposure(worn_data)\n",
    "\n",
    "        return {\n",
    "            'id': participant_id,\n",
    "        } | no_motion_stats | circadian_rhythm_stats | physical_activity_stats | activity_transition_stats | activity_light_stats\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'id': participant_id}\n",
    "\n",
    "def load_time_series(dir_name):\n",
    "    \n",
    "    participant_ids = os.listdir(dir_name)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        #tqdm: Wraps the executor.map iterable with tqdm -> Show a progress bar indicating the processing status\n",
    "        results = list(tqdm(executor.map(lambda x: process_file(os.path.join(dir_name, x, 'part-0.parquet'), x), participant_ids), total=len(participant_ids)))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    # Replace inf and -inf with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Replace NaN with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    df['BMI_PHR'] = df['Physical-BMI'] * df['Physical-HeartRate']\n",
    "\n",
    "    # Replace any remaining inf values with NaN\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [03:18<00:00,  5.01it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ts = load_time_series(\"../data/series_train.parquet\")\n",
    "test_ts = load_time_series(\"../data/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A small modification enables consistant formats for both time-series and tabular data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts['id'] = train_ts['id'].str.replace('id=', '')\n",
    "test_ts['id'] = test_ts['id'].str.replace('id=', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As mentioned in section 1.1, the tabular data contains columns that appear only in the training set, with the exception of \"sii,\" which is the target variable. Specifically, the columns related to the PCIAT calculation are present only in the training set and must be excluded to ensure data consistency between the training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PCIAT-PCIAT_01',\n",
       " 'PCIAT-PCIAT_02',\n",
       " 'PCIAT-PCIAT_03',\n",
       " 'PCIAT-PCIAT_04',\n",
       " 'PCIAT-PCIAT_05',\n",
       " 'PCIAT-PCIAT_06',\n",
       " 'PCIAT-PCIAT_07',\n",
       " 'PCIAT-PCIAT_08',\n",
       " 'PCIAT-PCIAT_09',\n",
       " 'PCIAT-PCIAT_10',\n",
       " 'PCIAT-PCIAT_11',\n",
       " 'PCIAT-PCIAT_12',\n",
       " 'PCIAT-PCIAT_13',\n",
       " 'PCIAT-PCIAT_14',\n",
       " 'PCIAT-PCIAT_15',\n",
       " 'PCIAT-PCIAT_16',\n",
       " 'PCIAT-PCIAT_17',\n",
       " 'PCIAT-PCIAT_18',\n",
       " 'PCIAT-PCIAT_19',\n",
       " 'PCIAT-PCIAT_20',\n",
       " 'PCIAT-PCIAT_Total',\n",
       " 'PCIAT-Season',\n",
       " 'sii']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "dif_cols = sorted(list(train_cols - test_cols))\n",
    "\n",
    "dif_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate 'sii' values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few SII scores are still derived from the sum of NAN values in PICAT questions, leading to potentially invalid SII values. The below cell tries to estimate the severity of internet usage SII based on current SII and the maximum possible SII.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCIAT_cols = [f'PCIAT-PCIAT_{i+1:02d}' for i in range(20)]\n",
    "\n",
    "#Recalculates the SII value based on the the current PCIAT values and the possible maximum PCIAT values\n",
    "def recalculate_sii(row):\n",
    "    value = 0\n",
    "    if (not pd.isna(row['PCIAT-PCIAT_Total'])):\n",
    "        value = row['PCIAT-PCIAT_Total']\n",
    "        \n",
    "    max_possible = value + row[PCIAT_cols].isna().sum() * 5\n",
    "    \n",
    "    if value <= 30 and max_possible <= 30:\n",
    "        return 0\n",
    "    elif 31 <= value <= 49 and max_possible <= 49:\n",
    "        return 1\n",
    "    elif 50 <= value <= 79 and max_possible <= 79:\n",
    "        return 2\n",
    "    elif value >= 80 and max_possible >= 80:\n",
    "        return 3\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "train['recalc_sii'] = train.apply(recalculate_sii, axis=1)\n",
    "train['sii'] = train['recalc_sii']\n",
    "train.drop(columns='recalc_sii', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a look at the test set after grafting encoded time-series data. As shown below, the participants who didn't wear device have features related to time-series values are NaN. To handle, we will fill all NaN values via KNNImputer trained on data in training set from those who worn devices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>std_moderate_act_total_duration</th>\n",
       "      <th>mean_moderate_act_count_periods</th>\n",
       "      <th>median_moderate_act_count_periods</th>\n",
       "      <th>max_moderate_act_count_periods</th>\n",
       "      <th>std_moderate_act_count_periods</th>\n",
       "      <th>mean_count_transitions</th>\n",
       "      <th>median_count_transitions</th>\n",
       "      <th>max_count_transitions</th>\n",
       "      <th>std_count_transitions</th>\n",
       "      <th>correlation_light_enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>61.352805</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888523</td>\n",
       "      <td>0.129729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0  00008ff9                      Fall                5                0   \n",
       "1  000fd460                    Summer                9                0   \n",
       "2  00105258                    Summer               10                1   \n",
       "3  00115b9f                    Winter                9                0   \n",
       "4  0016bb22                    Spring               18                1   \n",
       "\n",
       "  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0      Winter             51.0            Fall     16.877316             46.0   \n",
       "1         NaN              NaN            Fall     14.035590             48.0   \n",
       "2        Fall             71.0            Fall     16.648696             56.5   \n",
       "3        Fall             71.0          Summer     18.292347             56.0   \n",
       "4      Summer              NaN             NaN           NaN              NaN   \n",
       "\n",
       "   Physical-Weight  ...  std_moderate_act_total_duration  \\\n",
       "0             50.8  ...                              NaN   \n",
       "1             46.0  ...                              NaN   \n",
       "2             75.6  ...                              NaN   \n",
       "3             81.6  ...                        61.352805   \n",
       "4              NaN  ...                              NaN   \n",
       "\n",
       "   mean_moderate_act_count_periods  median_moderate_act_count_periods  \\\n",
       "0                              NaN                                NaN   \n",
       "1                              NaN                                NaN   \n",
       "2                              NaN                                NaN   \n",
       "3                         1.166667                                1.0   \n",
       "4                              NaN                                NaN   \n",
       "\n",
       "   max_moderate_act_count_periods std_moderate_act_count_periods  \\\n",
       "0                             NaN                            NaN   \n",
       "1                             NaN                            NaN   \n",
       "2                             NaN                            NaN   \n",
       "3                             2.0                       0.408248   \n",
       "4                             NaN                            NaN   \n",
       "\n",
       "   mean_count_transitions  median_count_transitions  max_count_transitions  \\\n",
       "0                     NaN                       NaN                    NaN   \n",
       "1                     NaN                       NaN                    NaN   \n",
       "2                     NaN                       NaN                    NaN   \n",
       "3                     1.5                       1.0                    3.0   \n",
       "4                     NaN                       NaN                    NaN   \n",
       "\n",
       "  std_count_transitions  correlation_light_enmo  \n",
       "0                   NaN                     NaN  \n",
       "1                   NaN                     NaN  \n",
       "2                   NaN                     NaN  \n",
       "3              0.888523                0.129729  \n",
       "4                   NaN                     NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values for numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize a KNNImputer for handling missing values. Statistically, KNNImputer outweights SimpleImputer in this context. However, it encounters the computationally expensive cost, and the requirement of hyperparameter K (K value should be considered to change later). The imputation should be applied on both train and test set. However, to avoid data leakage, the imputer has to be trained on data from training set, then appied to both train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_imputation(train_df, test_df):\n",
    "    numeric_cols = train_df.select_dtypes(include=['float64', 'int64', 'int32', 'float32']).columns.tolist()\n",
    "    \n",
    "    numeric_cols = [col for col in numeric_cols if col not in dif_cols]\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    #Fit on training set\n",
    "    imputer.fit(train_df[numeric_cols])\n",
    "\n",
    "    #Transform both\n",
    "    train_df[numeric_cols] = imputer.transform(train_df[numeric_cols])\n",
    "    test_df[numeric_cols] = imputer.transform(test_df[numeric_cols])\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = numeric_imputation(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>std_moderate_act_total_duration</th>\n",
       "      <th>mean_moderate_act_count_periods</th>\n",
       "      <th>median_moderate_act_count_periods</th>\n",
       "      <th>max_moderate_act_count_periods</th>\n",
       "      <th>std_moderate_act_count_periods</th>\n",
       "      <th>mean_count_transitions</th>\n",
       "      <th>median_count_transitions</th>\n",
       "      <th>max_count_transitions</th>\n",
       "      <th>std_count_transitions</th>\n",
       "      <th>correlation_light_enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.00</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>386.547341</td>\n",
       "      <td>5.975914</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.263757</td>\n",
       "      <td>8.655200</td>\n",
       "      <td>7.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.767433</td>\n",
       "      <td>0.132322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.8</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>309.145707</td>\n",
       "      <td>6.837425</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2.756057</td>\n",
       "      <td>6.126791</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.862391</td>\n",
       "      <td>0.178144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.50</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>255.959519</td>\n",
       "      <td>4.193237</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.397566</td>\n",
       "      <td>4.494649</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3.774495</td>\n",
       "      <td>0.210945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.00</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>61.352805</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888523</td>\n",
       "      <td>0.129729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.713639</td>\n",
       "      <td>62.54</td>\n",
       "      <td>123.8</td>\n",
       "      <td>...</td>\n",
       "      <td>486.388753</td>\n",
       "      <td>5.023333</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2.954711</td>\n",
       "      <td>6.803429</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.194390</td>\n",
       "      <td>0.149184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0  00008ff9                      Fall              5.0              0.0   \n",
       "1  000fd460                    Summer              9.0              0.0   \n",
       "2  00105258                    Summer             10.0              1.0   \n",
       "3  00115b9f                    Winter              9.0              0.0   \n",
       "4  0016bb22                    Spring             18.0              1.0   \n",
       "\n",
       "  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0      Winter             51.0            Fall     16.877316            46.00   \n",
       "1         NaN             68.8            Fall     14.035590            48.00   \n",
       "2        Fall             71.0            Fall     16.648696            56.50   \n",
       "3        Fall             71.0          Summer     18.292347            56.00   \n",
       "4      Summer             71.0             NaN     26.713639            62.54   \n",
       "\n",
       "   Physical-Weight  ...  std_moderate_act_total_duration  \\\n",
       "0             50.8  ...                       386.547341   \n",
       "1             46.0  ...                       309.145707   \n",
       "2             75.6  ...                       255.959519   \n",
       "3             81.6  ...                        61.352805   \n",
       "4            123.8  ...                       486.388753   \n",
       "\n",
       "   mean_moderate_act_count_periods  median_moderate_act_count_periods  \\\n",
       "0                         5.975914                                4.8   \n",
       "1                         6.837425                                5.6   \n",
       "2                         4.193237                                3.7   \n",
       "3                         1.166667                                1.0   \n",
       "4                         5.023333                                4.2   \n",
       "\n",
       "   max_moderate_act_count_periods std_moderate_act_count_periods  \\\n",
       "0                            17.0                       4.263757   \n",
       "1                            13.6                       2.756057   \n",
       "2                             9.0                       2.397566   \n",
       "3                             2.0                       0.408248   \n",
       "4                            11.6                       2.954711   \n",
       "\n",
       "   mean_count_transitions  median_count_transitions  max_count_transitions  \\\n",
       "0                8.655200                       7.4                   22.0   \n",
       "1                6.126791                       5.0                   17.6   \n",
       "2                4.494649                       3.4                   14.6   \n",
       "3                1.500000                       1.0                    3.0   \n",
       "4                6.803429                       6.4                   16.2   \n",
       "\n",
       "  std_count_transitions  correlation_light_enmo  \n",
       "0              5.767433                0.132322  \n",
       "1              4.862391                0.178144  \n",
       "2              3.774495                0.210945  \n",
       "3              0.888523                0.129729  \n",
       "4              4.194390                0.149184  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get categorical columns\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "#File the nan values in categorical collumns with 'Missing'\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "#Convert from categorical to numeric \n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping = create_mapping(col, train)\n",
    "    mappingTe = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping).astype(int)\n",
    "    test[col] = test[col].replace(mappingTe).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>std_moderate_act_total_duration</th>\n",
       "      <th>mean_moderate_act_count_periods</th>\n",
       "      <th>median_moderate_act_count_periods</th>\n",
       "      <th>max_moderate_act_count_periods</th>\n",
       "      <th>std_moderate_act_count_periods</th>\n",
       "      <th>mean_count_transitions</th>\n",
       "      <th>median_count_transitions</th>\n",
       "      <th>max_count_transitions</th>\n",
       "      <th>std_count_transitions</th>\n",
       "      <th>correlation_light_enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.00</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>386.547341</td>\n",
       "      <td>5.975914</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.263757</td>\n",
       "      <td>8.655200</td>\n",
       "      <td>7.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.767433</td>\n",
       "      <td>0.132322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.8</td>\n",
       "      <td>0</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>309.145707</td>\n",
       "      <td>6.837425</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2.756057</td>\n",
       "      <td>6.126791</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.862391</td>\n",
       "      <td>0.178144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.50</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>255.959519</td>\n",
       "      <td>4.193237</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.397566</td>\n",
       "      <td>4.494649</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3.774495</td>\n",
       "      <td>0.210945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.00</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>61.352805</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888523</td>\n",
       "      <td>0.129729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.713639</td>\n",
       "      <td>62.54</td>\n",
       "      <td>123.8</td>\n",
       "      <td>...</td>\n",
       "      <td>486.388753</td>\n",
       "      <td>5.023333</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2.954711</td>\n",
       "      <td>6.803429</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.194390</td>\n",
       "      <td>0.149184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0  00008ff9                          0              5.0              0.0   \n",
       "1  000fd460                          1              9.0              0.0   \n",
       "2  00105258                          1             10.0              1.0   \n",
       "3  00115b9f                          2              9.0              0.0   \n",
       "4  0016bb22                          3             18.0              1.0   \n",
       "\n",
       "   CGAS-Season  CGAS-CGAS_Score  Physical-Season  Physical-BMI  \\\n",
       "0            0             51.0                0     16.877316   \n",
       "1            1             68.8                0     14.035590   \n",
       "2            2             71.0                0     16.648696   \n",
       "3            2             71.0                1     18.292347   \n",
       "4            3             71.0                2     26.713639   \n",
       "\n",
       "   Physical-Height  Physical-Weight  ...  std_moderate_act_total_duration  \\\n",
       "0            46.00             50.8  ...                       386.547341   \n",
       "1            48.00             46.0  ...                       309.145707   \n",
       "2            56.50             75.6  ...                       255.959519   \n",
       "3            56.00             81.6  ...                        61.352805   \n",
       "4            62.54            123.8  ...                       486.388753   \n",
       "\n",
       "   mean_moderate_act_count_periods  median_moderate_act_count_periods  \\\n",
       "0                         5.975914                                4.8   \n",
       "1                         6.837425                                5.6   \n",
       "2                         4.193237                                3.7   \n",
       "3                         1.166667                                1.0   \n",
       "4                         5.023333                                4.2   \n",
       "\n",
       "   max_moderate_act_count_periods  std_moderate_act_count_periods  \\\n",
       "0                            17.0                        4.263757   \n",
       "1                            13.6                        2.756057   \n",
       "2                             9.0                        2.397566   \n",
       "3                             2.0                        0.408248   \n",
       "4                            11.6                        2.954711   \n",
       "\n",
       "   mean_count_transitions  median_count_transitions  max_count_transitions  \\\n",
       "0                8.655200                       7.4                   22.0   \n",
       "1                6.126791                       5.0                   17.6   \n",
       "2                4.494649                       3.4                   14.6   \n",
       "3                1.500000                       1.0                    3.0   \n",
       "4                6.803429                       6.4                   16.2   \n",
       "\n",
       "   std_count_transitions  correlation_light_enmo  \n",
       "0               5.767433                0.132322  \n",
       "1               4.862391                0.178144  \n",
       "2               3.774495                0.210945  \n",
       "3               0.888523                0.129729  \n",
       "4               4.194390                0.149184  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feature_engineering(train)\n",
    "#Remove rows which has got fewer than 10 non-null values\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test  = test .drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As mentioned in section 1.1, many features in tabular data have a significant number of missing values. For example, columns like PAQ_A-Season and PAQ_A-PAQ_A_Total are missing nearly 90% of their values. Therefore, it is essential to select columns that are relevant and consistent, as this will enhance the efficiency of model building. The cell below highlights the features we have identified and evaluated as important.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii',\n",
    "                'BMI_Age','Internet_Hours_Age','BMI_Internet_Hours',\n",
    "                'BFP_BMI', 'FFMI_BFP', 'FMI_BFP', 'LST_TBW', 'BFP_BMR', 'BFP_DEE', 'BMR_Weight', 'DEE_Weight',\n",
    "                'SMM_Height', 'Muscle_to_Fat', 'Hydration_Status', 'ICW_TBW','BMI_PHR']\n",
    "\n",
    "featuresCols += train_ts.columns.tolist()\n",
    "featuresCols.remove('id')\n",
    "\n",
    "train = train[featuresCols]\n",
    "\n",
    "featuresCols.remove('sii')\n",
    "test = test[featuresCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check and replace any INF values with NaN\n",
    "if np.any(np.isinf(train)):\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The cell below checks for any NaN (Not a Number) values in the training dataset. Even though imputation has been performed previously, it is still possible for unwanted values like INF (infinity) or NaN to be generated during the feature engineering process. Rechecking the data ensures that the dataset is completely clean, which helps to avoid issues during model building.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with NaN values:\n",
      "--------------------------------------------------\n",
      "sii                               1241 NaN values ( 31.34%)\n",
      "BMR_Weight                          63 NaN values (  1.59%)\n",
      "DEE_Weight                          63 NaN values (  1.59%)\n",
      "Hydration_Status                    63 NaN values (  1.59%)\n",
      "\n",
      "Total columns with NaN values: 4\n"
     ]
    }
   ],
   "source": [
    "df = train\n",
    "# Get columns with NaN values\n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Calculate number of NaN values per column\n",
    "nan_counts = df[nan_columns].isna().sum()\n",
    "\n",
    "# Sort by number of NaN values (descending)\n",
    "nan_counts_sorted = nan_counts.sort_values(ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nColumns with NaN values:\")\n",
    "print(\"-\" * 50)\n",
    "for col, count in nan_counts_sorted.items():\n",
    "    total = len(df)\n",
    "    percentage = (count/total * 100)\n",
    "    print(f\"{col:<30} {count:>7} NaN values ({percentage:>6.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal columns with NaN values: {len(nan_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside from the sii column, which has nearly one-third of its data missing (we will discuss how to handle this in the next section 2. and 3.), other columns like BMR_Weight, DEE_Weight, and Hydration_Status also have missing data. These columns are new compared to the original dataset and were created during the feature engineering process. However, with the percentage of missing data being only 1.59%, we decided to remove the rows containing NaN values. This small fraction of data is unlikely to affect the quality and reliability of entire dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['BMR_Weight', 'DEE_Weight', 'Hydration_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3897, 136) (20, 135)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>...</th>\n",
       "      <th>std_moderate_act_total_duration</th>\n",
       "      <th>mean_moderate_act_count_periods</th>\n",
       "      <th>median_moderate_act_count_periods</th>\n",
       "      <th>max_moderate_act_count_periods</th>\n",
       "      <th>std_moderate_act_count_periods</th>\n",
       "      <th>mean_count_transitions</th>\n",
       "      <th>median_count_transitions</th>\n",
       "      <th>max_count_transitions</th>\n",
       "      <th>std_count_transitions</th>\n",
       "      <th>correlation_light_enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.00</td>\n",
       "      <td>50.8</td>\n",
       "      <td>23.2</td>\n",
       "      <td>...</td>\n",
       "      <td>386.547341</td>\n",
       "      <td>5.975914</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.263757</td>\n",
       "      <td>8.655200</td>\n",
       "      <td>7.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.767433</td>\n",
       "      <td>0.132322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.8</td>\n",
       "      <td>0</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>309.145707</td>\n",
       "      <td>6.837425</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2.756057</td>\n",
       "      <td>6.126791</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.862391</td>\n",
       "      <td>0.178144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.50</td>\n",
       "      <td>75.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.959519</td>\n",
       "      <td>4.193237</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.397566</td>\n",
       "      <td>4.494649</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3.774495</td>\n",
       "      <td>0.210945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.00</td>\n",
       "      <td>81.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.352805</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888523</td>\n",
       "      <td>0.129729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.713639</td>\n",
       "      <td>62.54</td>\n",
       "      <td>123.8</td>\n",
       "      <td>33.6</td>\n",
       "      <td>...</td>\n",
       "      <td>486.388753</td>\n",
       "      <td>5.023333</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2.954711</td>\n",
       "      <td>6.803429</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.194390</td>\n",
       "      <td>0.149184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  CGAS-Season  \\\n",
       "0                          0              5.0              0.0            0   \n",
       "1                          1              9.0              0.0            1   \n",
       "2                          1             10.0              1.0            2   \n",
       "3                          2              9.0              0.0            2   \n",
       "4                          3             18.0              1.0            3   \n",
       "\n",
       "   CGAS-CGAS_Score  Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0             51.0                0     16.877316            46.00   \n",
       "1             68.8                0     14.035590            48.00   \n",
       "2             71.0                0     16.648696            56.50   \n",
       "3             71.0                1     18.292347            56.00   \n",
       "4             71.0                2     26.713639            62.54   \n",
       "\n",
       "   Physical-Weight  Physical-Waist_Circumference  ...  \\\n",
       "0             50.8                          23.2  ...   \n",
       "1             46.0                          22.0  ...   \n",
       "2             75.6                          25.0  ...   \n",
       "3             81.6                          26.0  ...   \n",
       "4            123.8                          33.6  ...   \n",
       "\n",
       "   std_moderate_act_total_duration  mean_moderate_act_count_periods  \\\n",
       "0                       386.547341                         5.975914   \n",
       "1                       309.145707                         6.837425   \n",
       "2                       255.959519                         4.193237   \n",
       "3                        61.352805                         1.166667   \n",
       "4                       486.388753                         5.023333   \n",
       "\n",
       "   median_moderate_act_count_periods  max_moderate_act_count_periods  \\\n",
       "0                                4.8                            17.0   \n",
       "1                                5.6                            13.6   \n",
       "2                                3.7                             9.0   \n",
       "3                                1.0                             2.0   \n",
       "4                                4.2                            11.6   \n",
       "\n",
       "   std_moderate_act_count_periods  mean_count_transitions  \\\n",
       "0                        4.263757                8.655200   \n",
       "1                        2.756057                6.126791   \n",
       "2                        2.397566                4.494649   \n",
       "3                        0.408248                1.500000   \n",
       "4                        2.954711                6.803429   \n",
       "\n",
       "   median_count_transitions  max_count_transitions  std_count_transitions  \\\n",
       "0                       7.4                   22.0               5.767433   \n",
       "1                       5.0                   17.6               4.862391   \n",
       "2                       3.4                   14.6               3.774495   \n",
       "3                       1.0                    3.0               0.888523   \n",
       "4                       6.4                   16.2               4.194390   \n",
       "\n",
       "   correlation_light_enmo  \n",
       "0                0.132322  \n",
       "1                0.178144  \n",
       "2                0.210945  \n",
       "3                0.129729  \n",
       "4                0.149184  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
