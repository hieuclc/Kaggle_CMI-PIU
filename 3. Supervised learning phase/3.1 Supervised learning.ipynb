{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76851611",
   "metadata": {
    "papermill": {
     "duration": 0.005791,
     "end_time": "2024-12-19T14:29:39.470531",
     "exception": false,
     "start_time": "2024-12-19T14:29:39.464740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab00998",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-19T14:29:39.481358Z",
     "iopub.status.busy": "2024-12-19T14:29:39.481083Z",
     "iopub.status.idle": "2024-12-19T14:30:03.024014Z",
     "shell.execute_reply": "2024-12-19T14:30:03.023330Z"
    },
    "papermill": {
     "duration": 23.550533,
     "end_time": "2024-12-19T14:30:03.025985",
     "exception": false,
     "start_time": "2024-12-19T14:29:39.475452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import torch\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from colorama import Fore, Style\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa37bee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:30:03.038641Z",
     "iopub.status.busy": "2024-12-19T14:30:03.037858Z",
     "iopub.status.idle": "2024-12-19T14:30:03.050679Z",
     "shell.execute_reply": "2024-12-19T14:30:03.049631Z"
    },
    "papermill": {
     "duration": 0.021736,
     "end_time": "2024-12-19T14:30:03.052909",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.031173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075a4ca",
   "metadata": {
    "papermill": {
     "duration": 0.005422,
     "end_time": "2024-12-19T14:30:03.064590",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.059168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9884932",
   "metadata": {
    "papermill": {
     "duration": 0.007214,
     "end_time": "2024-12-19T14:30:03.080962",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.073748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50888798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:30:03.095421Z",
     "iopub.status.busy": "2024-12-19T14:30:03.095055Z",
     "iopub.status.idle": "2024-12-19T14:30:03.133009Z",
     "shell.execute_reply": "2024-12-19T14:30:03.132179Z"
    },
    "papermill": {
     "duration": 0.046106,
     "end_time": "2024-12-19T14:30:03.134743",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.088637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dictionary_of_statistics(data, time = None):\n",
    "    try:\n",
    "        #Handle empty dataframe\n",
    "        if (data.empty or len(data.columns) == 0 or data is None):\n",
    "            return {}\n",
    "        \n",
    "        if len(data.columns) == 0:\n",
    "            return {}\n",
    "        \n",
    "        #Aggreate statistics for the dictionary\n",
    "        stats_summary = data.agg(['mean', 'median', 'max', 'std']).to_dict()\n",
    "        \n",
    "        flattened_stats = {}\n",
    "        for col, stats in stats_summary.items():\n",
    "            for stat_name, value in stats.items():\n",
    "                key = f\"{stat_name}_{col}\"\n",
    "                if (time is not None):\n",
    "                    key = f\"{stat_name}_{col}_{time}\"\n",
    "                flattened_stats[key] = value\n",
    "        \n",
    "        return flattened_stats\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "#Feature engineering\n",
    "\n",
    "def compute_time_features(data, day_start_hour=6, day_end_hour=18, expected_diff=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute and add time-related features to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'time_of_day' in nanosecond and 'relative_date_PCIAT'.\n",
    "    - day_start_hour (int): Hour to start the day period. Default is 8.\n",
    "    - day_end_hour (int): Hour to end the day period. Default is 21.\n",
    "    - expected_diff (int): Expected time difference between steps in seconds. Default is 5.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #From nanosecond to hour in a day\n",
    "    data['time_of_day_hours'] = data['time_of_day'] / 1e9 / 3600\n",
    "    data['day_time'] = data['relative_date_PCIAT'] + data['time_of_day_hours'] / 24\n",
    "    \n",
    "    #Categorize the day and night based on time data\n",
    "    \n",
    "    data['day_period'] = np.where(\n",
    "        (data['time_of_day_hours'] >= day_start_hour) &\n",
    "        (data['time_of_day_hours'] < day_end_hour),\n",
    "        'day', 'night'\n",
    "    )\n",
    "    \n",
    "    #Time difference beween steps\n",
    "    #As the description, the time_of_day should represent the start of a 5s window over which the data was sampled\n",
    "    #Calculate the time difference between each step\n",
    "    data['time_diff'] = (data['day_time'].diff() * 86400).round(0) # seconds in a day\n",
    "    data['measurement_after_gap'] = data['time_diff'] > expected_diff\n",
    "    \n",
    "def no_motion_periods(worn_data):\n",
    "    \"\"\"\n",
    "    Find periods of no motion and give analytical insights in the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'time_of_day' and 'relative_date_PCIAT'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with new features: \n",
    "    + total duration of no motion periods per day\n",
    "    + the number of no motion periods per day.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Calculate no motion periods\n",
    "    no_motion = worn_data['enmo'] == 0\n",
    "    motion_group = (\n",
    "        (no_motion != no_motion.shift()) |\n",
    "        (worn_data['measurement_after_gap'])\n",
    "    ).cumsum()\n",
    "\n",
    "    no_motion_periods = worn_data[no_motion].groupby(\n",
    "        motion_group\n",
    "    )['day_time'].agg(['min', 'max'])\n",
    "\n",
    "    no_motion_periods['duration_sec'] = (\n",
    "        (no_motion_periods['max'] - no_motion_periods['min']) * 86400\n",
    "    ).round(0).astype(int)\n",
    "    \n",
    "    no_motion_periods['duration_sec'] += 5\n",
    "    no_motion_periods['day'] = no_motion_periods['min'].astype(int)\n",
    "    \n",
    "    # Calculate daily statistics on no motion periods\n",
    "    daily_stats = no_motion_periods.groupby(no_motion_periods['day']) \\\n",
    "        .agg(no_motion_duration=('duration_sec', 'sum'),\n",
    "            no_motion_count=('duration_sec', 'size'))\n",
    "    \n",
    "    #Aggreate statistics for the dictionary\n",
    "    return dictionary_of_statistics(daily_stats)\n",
    "\n",
    "def circadian_rhythm_analysis(worn_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Make features capturing the variation in activity across the 24-hour cycle, \n",
    "    separately for day and night times (or wakefulness and sleep periods).\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'time_of_day_hours', 'day_period' and 'relative_date_PCIAT'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: 2 DataFrame, corresponding to day and night times,  with new features capturing the circadian rhythm of the wearer,\n",
    "    + Standard deviation across hourly means per day\n",
    "    + Peak hour of activity per day\n",
    "    + Entropy of activity distribution per day\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if (worn_data.empty or worn_data is None):\n",
    "            return {}\n",
    "    \n",
    "        hourly_activity = worn_data.groupby(\n",
    "            [worn_data['relative_date_PCIAT'].astype(int),\n",
    "            worn_data['time_of_day_hours'].astype(int),\n",
    "            worn_data['day_period']]\n",
    "        )['enmo'].agg(['mean', 'max'])\n",
    "\n",
    "        features = hourly_activity['mean'].groupby(\n",
    "            ['relative_date_PCIAT', 'day_period']\n",
    "        ).agg(\n",
    "            std_across_hours='std',\n",
    "            peak_hour=lambda x: x.idxmax()[1],\n",
    "            entropy=lambda x: -(x / x.sum() * np.log(x / x.sum() + 1e-9)).sum()\n",
    "        )\n",
    "        \n",
    "        # Safely extract day/night features\n",
    "        try:\n",
    "            day_features = features.xs('day', level='day_period')\n",
    "        except:\n",
    "            day_features = pd.DataFrame()\n",
    "            \n",
    "        try:    \n",
    "            night_features = features.xs('night', level='day_period')\n",
    "        except:\n",
    "            night_features = pd.DataFrame()\n",
    "\n",
    "        return dictionary_of_statistics(day_features, time=\"day\") | dictionary_of_statistics(night_features, time='night')  \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def physical_activity_analysis(worn_data):\n",
    "        \n",
    "    \"\"\"\n",
    "    Analyze the Moderate to Vigorous Physical Activity (MVPA) based on a threshold of ENMO values, \n",
    "    and calculate the duration of the detected MVPA activity bouts\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'enmo', 'time_diff' and 'day_time'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with new features capturing the physical activity level of the wearer,\n",
    "    including:\n",
    "    + Total duration of MVPA per day\n",
    "    + Number of MVPA periods per day\n",
    "    \"\"\"\n",
    "    # In order to classify physical activity as MVPA, we only retained activities that lasted at least 1 minute and met the criteria for the 100 mg (= 0.1g) threshold\n",
    "    if worn_data is None or worn_data.empty:\n",
    "        return {}\n",
    "    \n",
    "    mvpa_threshold = 0.1\n",
    "    merge_gap = 60\n",
    "    \n",
    "    def merge_mvpa_groups(df, allowed_gap=60, merge_gap=60):\n",
    "        last_mvpa_time = df['day_time'].where(df['is_mvpa']).ffill().shift()\n",
    "        \n",
    "        mvpa_time_diff = (\n",
    "            (df['day_time'] - last_mvpa_time) * 86400\n",
    "        ).round(0)\n",
    "        \n",
    "        mvpa_group = (\n",
    "            (df['is_mvpa'] != df['is_mvpa'].shift()) |\n",
    "            (df['time_diff'] >= allowed_gap)\n",
    "        ).cumsum()\n",
    "        \n",
    "        is_mvpa_start = (\n",
    "            (mvpa_group != mvpa_group.shift()) &\n",
    "            df['is_mvpa']\n",
    "        )\n",
    "        \n",
    "        group_increment = is_mvpa_start & (\n",
    "            (mvpa_time_diff >= merge_gap) | last_mvpa_time.isnull()\n",
    "        )\n",
    "        \n",
    "        merged_group = group_increment.cumsum()\n",
    "        merged_group.loc[~df['is_mvpa']] = np.nan\n",
    "        \n",
    "        return merged_group\n",
    "    \n",
    "    worn_data['is_mvpa'] = worn_data['enmo'] > mvpa_threshold\n",
    "    worn_data['mvpa_merged_group'] = merge_mvpa_groups(worn_data)\n",
    "\n",
    "    mvpa_periods = worn_data[\n",
    "        worn_data['is_mvpa']\n",
    "    ].groupby('mvpa_merged_group')['day_time'].agg(['min', 'max'])\n",
    "\n",
    "    mvpa_periods['duration_sec'] = (\n",
    "        mvpa_periods['max'] - mvpa_periods['min']\n",
    "    ) * 86400  # days to seconds\n",
    "\n",
    "    mvpa_periods = mvpa_periods[mvpa_periods['duration_sec'] >= 60]\n",
    "    mvpa_periods['duration_min'] = mvpa_periods['duration_sec'] / 60\n",
    "    \n",
    "    mvpa_periods['day'] = mvpa_periods['min'].astype(int)\n",
    "\n",
    "    daily_stats = mvpa_periods.groupby(mvpa_periods['day']) \\\n",
    "        .agg(mvpa_total_duration=('duration_sec', 'sum'),\n",
    "            mvpa_count_periods=('duration_sec', 'size'))\n",
    "        \n",
    "    return dictionary_of_statistics(daily_stats)\n",
    "    \n",
    "def activity_transition_analysis(worn_data):\n",
    "        \n",
    "    \"\"\"\n",
    "    The analysis to look at transitions between low, moderate and vigorous activity. To smooth out sudden, \n",
    "    short bursts of different activities, we filter out segments with a duration below a 1 minute threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'enmo', 'time_diff' and 'day_time'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with new features capturing the activity transitions of the wearer,\n",
    "    + Total duration of different of activity per day\n",
    "    + Number of different activity periods per day\n",
    "    \"\"\"\n",
    "    mvpa_threshold = 0.1\n",
    "    vig_threshold = 0.5\n",
    "    worn_data['activity_type'] = pd.cut(\n",
    "        worn_data['enmo'],\n",
    "        bins=[-np.inf, mvpa_threshold, vig_threshold, np.inf],\n",
    "        labels=['low', 'moderate', 'vigorous']\n",
    "    )\n",
    "    activity_group = (\n",
    "        (worn_data['activity_type'] != worn_data['activity_type'].shift()) |\n",
    "        (worn_data['measurement_after_gap'])\n",
    "    ).cumsum()\n",
    "    \n",
    "    activity_periods = worn_data.groupby(activity_group).agg(\n",
    "        min=('day_time', 'min'),\n",
    "        max=('day_time', 'max'),\n",
    "        activity_type=('activity_type', 'first')\n",
    "    )\n",
    "    activity_periods['duration_sec'] = (\n",
    "        activity_periods['max'] - activity_periods['min']\n",
    "    ) * 86400 + 5 \n",
    "\n",
    "    activity_periods = activity_periods[activity_periods['duration_sec'] >= 60]\n",
    "    activity_periods['duration_min'] = activity_periods['duration_sec'] / 60\n",
    "    \n",
    "    activity_periods['day'] = activity_periods['min'].astype(int)\n",
    "    activity_periods['transition_num'] = (\n",
    "        activity_periods.groupby('day')['activity_type']\n",
    "        .apply(lambda x: (x != x.shift()).cumsum())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    low_activity = activity_periods[activity_periods['activity_type'] == 'low'].groupby('day').agg(\n",
    "        low_act_total_duration=('duration_sec', 'sum'),\n",
    "        low_act_count_periods=('duration_sec', 'size')\n",
    "    )\n",
    "    \n",
    "    moderate_activity = activity_periods[activity_periods['activity_type'] == 'moderate'].groupby('day').agg(\n",
    "            moderate_act_total_duration=('duration_sec', 'sum'),\n",
    "            moderate_act_count_periods=('duration_sec', 'size')\n",
    "    )\n",
    "\n",
    "        \n",
    "    daily_transitions = activity_periods.groupby('day').agg(\n",
    "        count_transitions=('transition_num', 'max')\n",
    "    )\n",
    "    \n",
    "    return dictionary_of_statistics(low_activity) | dictionary_of_statistics(moderate_activity) | dictionary_of_statistics(daily_transitions)\n",
    "\n",
    "def activity_light_exposure(worn_data):\n",
    "        \n",
    "    \"\"\"\n",
    "    Analyze the correlation between light exposure and physical activity level.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing 'light' and 'enmo'.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The correlation between light exposure and physical activity level.\n",
    "    \"\"\"\n",
    "    correlation_light_enmo = worn_data[['light', 'enmo']].corr().iloc[0, 1]\n",
    "    return {'correlation_light_enmo': correlation_light_enmo}\n",
    "\n",
    "def process_file(file_path, participant_id):\n",
    "    try:\n",
    "        data = pd.read_parquet(file_path)\n",
    "        \n",
    "        if data.empty:\n",
    "            return {'id': participant_id}\n",
    "        \n",
    "        required_columns = ['time_of_day', 'relative_date_PCIAT', 'enmo', 'non-wear_flag', 'light']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            return {'id': participant_id}\n",
    "\n",
    "        # Compute time features\n",
    "        compute_time_features(data)\n",
    "            \n",
    "        # Calculate the percentage of non-worn time\n",
    "        non_wear_percentage = (data['non-wear_flag'].sum() / len(data)) * 100\n",
    "        \n",
    "        # Filter out the worn data\n",
    "        worn_data = data[data['non-wear_flag'] == 0]\n",
    "        \n",
    "        if (worn_data.empty):\n",
    "            return {'id': participant_id}\n",
    "        \n",
    "        # recalculate time difference between rows and measurement_after_gap flag in the worn data\n",
    "        expected_diff = 5\n",
    "        worn_data['time_diff'] = (worn_data['day_time'].diff() * 86400).round(0)\n",
    "        worn_data['measurement_after_gap'] = worn_data['time_diff'] > expected_diff\n",
    "\n",
    "        # Compute no motion periods\n",
    "        no_motion_stats = no_motion_periods(worn_data)\n",
    "        # Circadian rhythm analysis\n",
    "        circadian_rhythm_stats = circadian_rhythm_analysis(worn_data)\n",
    "        # Physical activity analysis\n",
    "        physical_activity_stats = physical_activity_analysis(worn_data)\n",
    "        # Activity transition analysis\n",
    "        activity_transition_stats = activity_transition_analysis(worn_data)\n",
    "        # Compute activity light correlation\n",
    "        activity_light_stats = activity_light_exposure(worn_data)\n",
    "\n",
    "        return {\n",
    "            'id': participant_id,\n",
    "        } | no_motion_stats | circadian_rhythm_stats | physical_activity_stats | activity_transition_stats | activity_light_stats\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'id': participant_id}\n",
    "\n",
    "def load_time_series(dir_name):\n",
    "    \n",
    "    participant_ids = os.listdir(dir_name)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        #tqdm: Wraps the executor.map iterable with tqdm -> Show a progress bar indicating the processing status\n",
    "        results = list(tqdm(executor.map(lambda x: process_file(os.path.join(dir_name, x, 'part-0.parquet'), x), participant_ids), total=len(participant_ids)))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    # Replace inf and -inf with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Replace NaN with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983640f1",
   "metadata": {
    "papermill": {
     "duration": 0.00482,
     "end_time": "2024-12-19T14:30:03.144807",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.139987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd34841c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:30:03.156380Z",
     "iopub.status.busy": "2024-12-19T14:30:03.155626Z",
     "iopub.status.idle": "2024-12-19T14:30:03.162057Z",
     "shell.execute_reply": "2024-12-19T14:30:03.161353Z"
    },
    "papermill": {
     "duration": 0.013875,
     "end_time": "2024-12-19T14:30:03.163687",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.149812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    df['BMI_PHR'] = df['Physical-BMI'] * df['Physical-HeartRate']\n",
    "\n",
    "    # Replace any remaining inf values with NaN\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2e95a",
   "metadata": {
    "papermill": {
     "duration": 0.00469,
     "end_time": "2024-12-19T14:30:03.173532",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.168842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tabular KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6829fb3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:30:03.184520Z",
     "iopub.status.busy": "2024-12-19T14:30:03.184264Z",
     "iopub.status.idle": "2024-12-19T14:30:03.188918Z",
     "shell.execute_reply": "2024-12-19T14:30:03.188180Z"
    },
    "papermill": {
     "duration": 0.011889,
     "end_time": "2024-12-19T14:30:03.190434",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.178545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numeric_imputation(train_df, test_df, dif_cols):\n",
    "    numeric_cols = train_df.select_dtypes(include=['float64', 'int64', 'int32', 'float32']).columns.tolist()\n",
    "    \n",
    "    numeric_cols = [col for col in numeric_cols if col not in dif_cols]\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    #Fit on training set\n",
    "    imputer.fit(train_df[numeric_cols])\n",
    "\n",
    "    #Transform both\n",
    "    train_df[numeric_cols] = imputer.transform(train_df[numeric_cols])\n",
    "    test_df[numeric_cols] = imputer.transform(test_df[numeric_cols])\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3f4f2",
   "metadata": {
    "papermill": {
     "duration": 0.004803,
     "end_time": "2024-12-19T14:30:03.200163",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.195360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913d035",
   "metadata": {
    "papermill": {
     "duration": 0.004607,
     "end_time": "2024-12-19T14:30:03.209717",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.205110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4fdcc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:30:03.221158Z",
     "iopub.status.busy": "2024-12-19T14:30:03.220921Z",
     "iopub.status.idle": "2024-12-19T14:33:57.755122Z",
     "shell.execute_reply": "2024-12-19T14:33:57.754085Z"
    },
    "papermill": {
     "duration": 234.542279,
     "end_time": "2024-12-19T14:33:57.756858",
     "exception": false,
     "start_time": "2024-12-19T14:30:03.214579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [03:54<00:00,  4.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8c00dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:33:57.807072Z",
     "iopub.status.busy": "2024-12-19T14:33:57.806800Z",
     "iopub.status.idle": "2024-12-19T14:33:57.811972Z",
     "shell.execute_reply": "2024-12-19T14:33:57.811135Z"
    },
    "papermill": {
     "duration": 0.032009,
     "end_time": "2024-12-19T14:33:57.813754",
     "exception": false,
     "start_time": "2024-12-19T14:33:57.781745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ts['id'] = train_ts['id'].str.replace('id=', '')\n",
    "test_ts['id'] = test_ts['id'].str.replace('id=', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871977f",
   "metadata": {
    "papermill": {
     "duration": 0.023851,
     "end_time": "2024-12-19T14:33:57.864356",
     "exception": false,
     "start_time": "2024-12-19T14:33:57.840505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load tablular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba1b84c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:33:57.914168Z",
     "iopub.status.busy": "2024-12-19T14:33:57.913904Z",
     "iopub.status.idle": "2024-12-19T14:33:57.965526Z",
     "shell.execute_reply": "2024-12-19T14:33:57.964826Z"
    },
    "papermill": {
     "duration": 0.078683,
     "end_time": "2024-12-19T14:33:57.967466",
     "exception": false,
     "start_time": "2024-12-19T14:33:57.888783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d082d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:33:58.019214Z",
     "iopub.status.busy": "2024-12-19T14:33:58.018943Z",
     "iopub.status.idle": "2024-12-19T14:33:58.023616Z",
     "shell.execute_reply": "2024-12-19T14:33:58.022810Z"
    },
    "papermill": {
     "duration": 0.031354,
     "end_time": "2024-12-19T14:33:58.025297",
     "exception": false,
     "start_time": "2024-12-19T14:33:57.993943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'PCIAT-Season', 'sii']\n"
     ]
    }
   ],
   "source": [
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "dif_cols = sorted(list(train_cols - test_cols))\n",
    "\n",
    "print(dif_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7216a",
   "metadata": {
    "papermill": {
     "duration": 0.02373,
     "end_time": "2024-12-19T14:33:58.073030",
     "exception": false,
     "start_time": "2024-12-19T14:33:58.049300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fill sii with possible maximized PCIAT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd07e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:33:58.123544Z",
     "iopub.status.busy": "2024-12-19T14:33:58.123272Z",
     "iopub.status.idle": "2024-12-19T14:33:59.890899Z",
     "shell.execute_reply": "2024-12-19T14:33:59.890155Z"
    },
    "papermill": {
     "duration": 1.794872,
     "end_time": "2024-12-19T14:33:59.892806",
     "exception": false,
     "start_time": "2024-12-19T14:33:58.097934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PCIAT_cols = [f'PCIAT-PCIAT_{i+1:02d}' for i in range(20)]\n",
    "\n",
    "#Recalculates the SII value based on the the current PCIAT values and the possible maximum PCIAT values\n",
    "def recalculate_sii(row):\n",
    "    value = 0\n",
    "    if (not pd.isna(row['PCIAT-PCIAT_Total'])):\n",
    "        value = row['PCIAT-PCIAT_Total']\n",
    "        \n",
    "    max_possible = value + row[PCIAT_cols].isna().sum() * 5\n",
    "    \n",
    "    if value <= 30 and max_possible <= 30:\n",
    "        return 0\n",
    "    elif 31 <= value <= 49 and max_possible <= 49:\n",
    "        return 1\n",
    "    elif 50 <= value <= 79 and max_possible <= 79:\n",
    "        return 2\n",
    "    elif value >= 80 and max_possible >= 80:\n",
    "        return 3\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "train['recalc_sii'] = train.apply(recalculate_sii, axis=1)\n",
    "train['sii'] = train['recalc_sii']\n",
    "train.drop(columns='recalc_sii', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268fa6a",
   "metadata": {
    "papermill": {
     "duration": 0.023844,
     "end_time": "2024-12-19T14:33:59.941271",
     "exception": false,
     "start_time": "2024-12-19T14:33:59.917427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5ae8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:33:59.992096Z",
     "iopub.status.busy": "2024-12-19T14:33:59.991809Z",
     "iopub.status.idle": "2024-12-19T14:34:00.035439Z",
     "shell.execute_reply": "2024-12-19T14:34:00.034775Z"
    },
    "papermill": {
     "duration": 0.071474,
     "end_time": "2024-12-19T14:34:00.037149",
     "exception": false,
     "start_time": "2024-12-19T14:33:59.965675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_features = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "# Preprocessed time series\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "selected_features += time_series_cols\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)   \n",
    "\n",
    "train = train[selected_features]\n",
    "\n",
    "# Drop n/a values\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a018524",
   "metadata": {
    "papermill": {
     "duration": 0.024012,
     "end_time": "2024-12-19T14:34:00.085880",
     "exception": false,
     "start_time": "2024-12-19T14:34:00.061868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Handle missing values in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1837eb92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:34:00.135922Z",
     "iopub.status.busy": "2024-12-19T14:34:00.135601Z",
     "iopub.status.idle": "2024-12-19T14:34:05.697624Z",
     "shell.execute_reply": "2024-12-19T14:34:05.696943Z"
    },
    "papermill": {
     "duration": 5.589464,
     "end_time": "2024-12-19T14:34:05.699640",
     "exception": false,
     "start_time": "2024-12-19T14:34:00.110176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = numeric_imputation(train, test, dif_cols)\n",
    "train = feature_engineering(train)\n",
    "\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping = create_mapping(col, train)\n",
    "    mappingTe = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping).astype(int)\n",
    "    test[col] = test[col].replace(mappingTe).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240f868",
   "metadata": {
    "papermill": {
     "duration": 0.024363,
     "end_time": "2024-12-19T14:34:05.752409",
     "exception": false,
     "start_time": "2024-12-19T14:34:05.728046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Supervised learning phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdb4e8",
   "metadata": {
    "papermill": {
     "duration": 0.023881,
     "end_time": "2024-12-19T14:34:05.801304",
     "exception": false,
     "start_time": "2024-12-19T14:34:05.777423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Voting regressors with parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b03ebea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:34:05.851154Z",
     "iopub.status.busy": "2024-12-19T14:34:05.850403Z",
     "iopub.status.idle": "2024-12-19T14:37:32.470089Z",
     "shell.execute_reply": "2024-12-19T14:37:32.469226Z"
    },
    "papermill": {
     "duration": 206.646553,
     "end_time": "2024-12-19T14:37:32.471883",
     "exception": false,
     "start_time": "2024-12-19T14:34:05.825330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.893, lambda_l1=12, lambda_l2=0.01, learning_rate=0.04, max_depth=12, min_data_in_leaf=14, n_estimators=200, num_leaves=478; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.893, lambda_l1=12, lambda_l2=0.01, learning_rate=0.04, max_depth=12, min_data_in_leaf=14, n_estimators=200, num_leaves=478; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.893, lambda_l1=12, lambda_l2=0.01, learning_rate=0.04, max_depth=12, min_data_in_leaf=14, n_estimators=200, num_leaves=478; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=5, feature_fraction=0.893, lambda_l1=8, lambda_l2=0.02, learning_rate=0.04, max_depth=10, min_data_in_leaf=12, n_estimators=200, num_leaves=450; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=5, feature_fraction=0.893, lambda_l1=8, lambda_l2=0.02, learning_rate=0.04, max_depth=10, min_data_in_leaf=12, n_estimators=200, num_leaves=450; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=5, feature_fraction=0.893, lambda_l1=8, lambda_l2=0.02, learning_rate=0.04, max_depth=10, min_data_in_leaf=12, n_estimators=200, num_leaves=450; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=3, feature_fraction=0.88, lambda_l1=10, lambda_l2=0.005, learning_rate=0.046, max_depth=12, min_data_in_leaf=14, n_estimators=250, num_leaves=500; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=3, feature_fraction=0.88, lambda_l1=10, lambda_l2=0.005, learning_rate=0.046, max_depth=12, min_data_in_leaf=14, n_estimators=250, num_leaves=500; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=3, feature_fraction=0.88, lambda_l1=10, lambda_l2=0.005, learning_rate=0.046, max_depth=12, min_data_in_leaf=14, n_estimators=250, num_leaves=500; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.784, bagging_freq=5, feature_fraction=0.9, lambda_l1=10, lambda_l2=0.01, learning_rate=0.04, max_depth=10, min_data_in_leaf=12, n_estimators=300, num_leaves=478; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.784, bagging_freq=5, feature_fraction=0.9, lambda_l1=10, lambda_l2=0.01, learning_rate=0.04, max_depth=10, min_data_in_leaf=12, n_estimators=300, num_leaves=478; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.784, bagging_freq=5, feature_fraction=0.9, lambda_l1=10, lambda_l2=0.01, learning_rate=0.04, max_depth=10, min_data_in_leaf=12, n_estimators=300, num_leaves=478; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.88, lambda_l1=12, lambda_l2=0.01, learning_rate=0.046, max_depth=14, min_data_in_leaf=14, n_estimators=200, num_leaves=478; total time=   0.5s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.88, lambda_l1=12, lambda_l2=0.01, learning_rate=0.046, max_depth=14, min_data_in_leaf=14, n_estimators=200, num_leaves=478; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.88, lambda_l1=12, lambda_l2=0.01, learning_rate=0.046, max_depth=14, min_data_in_leaf=14, n_estimators=200, num_leaves=478; total time=   0.8s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=3, feature_fraction=0.9, lambda_l1=10, lambda_l2=0.01, learning_rate=0.04, max_depth=10, min_data_in_leaf=14, n_estimators=200, num_leaves=500; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=3, feature_fraction=0.9, lambda_l1=10, lambda_l2=0.01, learning_rate=0.04, max_depth=10, min_data_in_leaf=14, n_estimators=200, num_leaves=500; total time=   0.7s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=3, feature_fraction=0.9, lambda_l1=10, lambda_l2=0.01, learning_rate=0.04, max_depth=10, min_data_in_leaf=14, n_estimators=200, num_leaves=500; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=4, feature_fraction=0.9, lambda_l1=8, lambda_l2=0.01, learning_rate=0.046, max_depth=10, min_data_in_leaf=14, n_estimators=300, num_leaves=478; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=4, feature_fraction=0.9, lambda_l1=8, lambda_l2=0.01, learning_rate=0.046, max_depth=10, min_data_in_leaf=14, n_estimators=300, num_leaves=478; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=4, feature_fraction=0.9, lambda_l1=8, lambda_l2=0.01, learning_rate=0.046, max_depth=10, min_data_in_leaf=14, n_estimators=300, num_leaves=478; total time=   0.9s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.893, lambda_l1=8, lambda_l2=0.005, learning_rate=0.05, max_depth=12, min_data_in_leaf=14, n_estimators=250, num_leaves=478; total time=   0.8s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.893, lambda_l1=8, lambda_l2=0.005, learning_rate=0.05, max_depth=12, min_data_in_leaf=14, n_estimators=250, num_leaves=478; total time=   0.8s\n",
      "[CV] END bagging_fraction=0.79, bagging_freq=5, feature_fraction=0.893, lambda_l1=8, lambda_l2=0.005, learning_rate=0.05, max_depth=12, min_data_in_leaf=14, n_estimators=250, num_leaves=478; total time=   0.8s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=3, feature_fraction=0.9, lambda_l1=12, lambda_l2=0.01, learning_rate=0.05, max_depth=12, min_data_in_leaf=12, n_estimators=200, num_leaves=478; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=3, feature_fraction=0.9, lambda_l1=12, lambda_l2=0.01, learning_rate=0.05, max_depth=12, min_data_in_leaf=12, n_estimators=200, num_leaves=478; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=3, feature_fraction=0.9, lambda_l1=12, lambda_l2=0.01, learning_rate=0.05, max_depth=12, min_data_in_leaf=12, n_estimators=200, num_leaves=478; total time=   0.5s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=5, feature_fraction=0.893, lambda_l1=12, lambda_l2=0.005, learning_rate=0.046, max_depth=10, min_data_in_leaf=12, n_estimators=200, num_leaves=500; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=5, feature_fraction=0.893, lambda_l1=12, lambda_l2=0.005, learning_rate=0.046, max_depth=10, min_data_in_leaf=12, n_estimators=200, num_leaves=500; total time=   0.6s\n",
      "[CV] END bagging_fraction=0.78, bagging_freq=5, feature_fraction=0.893, lambda_l1=12, lambda_l2=0.005, learning_rate=0.046, max_depth=10, min_data_in_leaf=12, n_estimators=200, num_leaves=500; total time=   0.6s\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.045, max_depth=6, n_estimators=200, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.045, max_depth=6, n_estimators=200, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.045, max_depth=6, n_estimators=200, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.055, max_depth=5, n_estimators=250, random_state=42, reg_alpha=1.2, reg_lambda=6, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.055, max_depth=5, n_estimators=250, random_state=42, reg_alpha=1.2, reg_lambda=6, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.055, max_depth=5, n_estimators=250, random_state=42, reg_alpha=1.2, reg_lambda=6, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=250, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=250, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=250, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, random_state=42, reg_alpha=1, reg_lambda=6, subsample=0.75; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, random_state=42, reg_alpha=1, reg_lambda=6, subsample=0.75; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, random_state=42, reg_alpha=1, reg_lambda=6, subsample=0.75; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.045, max_depth=7, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=4, subsample=0.75; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.045, max_depth=7, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=4, subsample=0.75; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.045, max_depth=7, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=4, subsample=0.75; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.055, max_depth=7, n_estimators=250, random_state=42, reg_alpha=1, reg_lambda=4, subsample=0.75; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.055, max_depth=7, n_estimators=250, random_state=42, reg_alpha=1, reg_lambda=4, subsample=0.75; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.055, max_depth=7, n_estimators=250, random_state=42, reg_alpha=1, reg_lambda=4, subsample=0.75; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=7, n_estimators=250, random_state=42, reg_alpha=0.8, reg_lambda=6, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=7, n_estimators=250, random_state=42, reg_alpha=0.8, reg_lambda=6, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=7, n_estimators=250, random_state=42, reg_alpha=0.8, reg_lambda=6, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.055, max_depth=5, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.055, max_depth=5, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.055, max_depth=5, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=5, subsample=0.85; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=150, random_state=42, reg_alpha=0.8, reg_lambda=6, subsample=0.75; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=150, random_state=42, reg_alpha=0.8, reg_lambda=6, subsample=0.75; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=150, random_state=42, reg_alpha=0.8, reg_lambda=6, subsample=0.75; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.045, max_depth=5, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=6, subsample=0.75; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.045, max_depth=5, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=6, subsample=0.75; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.045, max_depth=5, n_estimators=150, random_state=42, reg_alpha=1.2, reg_lambda=6, subsample=0.75; total time=   1.2s\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=10, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.8s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=10, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.7s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=10, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.7s\n",
      "[CV] END depth=5, iterations=150, l2_leaf_reg=8, learning_rate=0.045, random_seed=42, verbose=0; total time=   1.3s\n",
      "[CV] END depth=5, iterations=150, l2_leaf_reg=8, learning_rate=0.045, random_seed=42, verbose=0; total time=   1.3s\n",
      "[CV] END depth=5, iterations=150, l2_leaf_reg=8, learning_rate=0.045, random_seed=42, verbose=0; total time=   1.3s\n",
      "[CV] END depth=5, iterations=250, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.7s\n",
      "[CV] END depth=5, iterations=250, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.6s\n",
      "[CV] END depth=5, iterations=250, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.6s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.7s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   3.0s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.9s\n",
      "[CV] END depth=5, iterations=250, l2_leaf_reg=8, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.6s\n",
      "[CV] END depth=5, iterations=250, l2_leaf_reg=8, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.7s\n",
      "[CV] END depth=5, iterations=250, l2_leaf_reg=8, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.6s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=8, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.9s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=8, learning_rate=0.05, random_seed=42, verbose=0; total time=   3.0s\n",
      "[CV] END depth=6, iterations=150, l2_leaf_reg=8, learning_rate=0.05, random_seed=42, verbose=0; total time=   3.1s\n",
      "[CV] END depth=5, iterations=200, l2_leaf_reg=8, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.1s\n",
      "[CV] END depth=5, iterations=200, l2_leaf_reg=8, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.1s\n",
      "[CV] END depth=5, iterations=200, l2_leaf_reg=8, learning_rate=0.05, random_seed=42, verbose=0; total time=   2.1s\n",
      "[CV] END depth=7, iterations=200, l2_leaf_reg=12, learning_rate=0.05, random_seed=42, verbose=0; total time=   9.4s\n",
      "[CV] END depth=7, iterations=200, l2_leaf_reg=12, learning_rate=0.05, random_seed=42, verbose=0; total time=   9.2s\n",
      "[CV] END depth=7, iterations=200, l2_leaf_reg=12, learning_rate=0.05, random_seed=42, verbose=0; total time=   9.1s\n",
      "[CV] END depth=5, iterations=150, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   1.3s\n",
      "[CV] END depth=5, iterations=150, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   1.3s\n",
      "[CV] END depth=5, iterations=150, l2_leaf_reg=10, learning_rate=0.05, random_seed=42, verbose=0; total time=   1.3s\n",
      "[CV] END depth=5, iterations=200, l2_leaf_reg=10, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.1s\n",
      "[CV] END depth=5, iterations=200, l2_leaf_reg=10, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.1s\n",
      "[CV] END depth=5, iterations=200, l2_leaf_reg=10, learning_rate=0.045, random_seed=42, verbose=0; total time=   2.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;catboost.core.CatBoostRegressor object at 0x7e7a82be9390&gt;,\n",
       "                   param_distributions={&#x27;depth&#x27;: [5, 6, 7],\n",
       "                                        &#x27;iterations&#x27;: [150, 200, 250],\n",
       "                                        &#x27;l2_leaf_reg&#x27;: [8, 10, 12],\n",
       "                                        &#x27;learning_rate&#x27;: [0.045, 0.05, 0.055],\n",
       "                                        &#x27;random_seed&#x27;: [42], &#x27;verbose&#x27;: [0]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;catboost.core.CatBoostRegressor object at 0x7e7a82be9390&gt;,\n",
       "                   param_distributions={&#x27;depth&#x27;: [5, 6, 7],\n",
       "                                        &#x27;iterations&#x27;: [150, 200, 250],\n",
       "                                        &#x27;l2_leaf_reg&#x27;: [8, 10, 12],\n",
       "                                        &#x27;learning_rate&#x27;: [0.045, 0.05, 0.055],\n",
       "                                        &#x27;random_seed&#x27;: [42], &#x27;verbose&#x27;: [0]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x7e7a82be9390&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x7e7a82be9390&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<catboost.core.CatBoostRegressor object at 0x7e7a82be9390>,\n",
       "                   param_distributions={'depth': [5, 6, 7],\n",
       "                                        'iterations': [150, 200, 250],\n",
       "                                        'l2_leaf_reg': [8, 10, 12],\n",
       "                                        'learning_rate': [0.045, 0.05, 0.055],\n",
       "                                        'random_seed': [42], 'verbose': [0]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm_param_grid = {\n",
    "    'learning_rate': [0.04, 0.046, 0.05],\n",
    "    'max_depth': [10, 12, 14],\n",
    "    'num_leaves': [450, 478, 500],\n",
    "    'min_data_in_leaf': [12, 13, 14],\n",
    "    'feature_fraction': [0.88, 0.893, 0.9],\n",
    "    'bagging_fraction': [0.78, 0.784, 0.79],\n",
    "    'bagging_freq': [3, 4, 5],\n",
    "    'lambda_l1': [8, 10, 12],\n",
    "    'lambda_l2': [0.005, 0.01, 0.02],\n",
    "    'n_estimators': [200, 250, 300]\n",
    "}\n",
    "\n",
    "\n",
    "xgboost_param_grid = {\n",
    "    'learning_rate': [0.045, 0.05, 0.055],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'subsample': [0.75, 0.8, 0.85],\n",
    "    'colsample_bytree': [0.75, 0.8, 0.85],\n",
    "    'reg_alpha': [0.8, 1, 1.2],\n",
    "    'reg_lambda': [4, 5, 6],\n",
    "    'random_state': [SEED]\n",
    "}\n",
    "\n",
    "\n",
    "catboost_param_grid = {\n",
    "    'learning_rate': [0.045, 0.05, 0.055],  # Around 0.05\n",
    "    'depth': [5, 6, 7],  # Around 6\n",
    "    'iterations': [150, 200, 250],  # Around 200\n",
    "    'l2_leaf_reg': [8, 10, 12],  # Around 10\n",
    "    'random_seed': [SEED],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "\n",
    "lgbm_model = LGBMRegressor(verbosity=-1)\n",
    "xgb_model = XGBRegressor(verbosity=0)\n",
    "catboost_model = CatBoostRegressor(cat_features=cat_c, verbose=0)\n",
    "\n",
    "lgbm_random = RandomizedSearchCV(estimator=lgbm_model, param_distributions=lightgbm_param_grid, \n",
    "                                  scoring='accuracy', cv=3, n_iter=10, verbose=2, random_state=SEED)\n",
    "\n",
    "xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=xgboost_param_grid, \n",
    "                                 scoring='accuracy', cv=3, n_iter=10, verbose=2, random_state=SEED)\n",
    "\n",
    "catboost_random = RandomizedSearchCV(estimator=catboost_model, param_distributions=catboost_param_grid, \n",
    "                                      scoring='accuracy', cv=3, n_iter=10, verbose=2, random_state=SEED)\n",
    "\n",
    "\n",
    "x_train_pd = train[[col for col in train.columns if col != 'sii']]\n",
    "y_train_pd = train['sii']\n",
    "\n",
    "\n",
    "lgbm_random.fit(x_train_pd, y_train_pd)\n",
    "xgb_random.fit(x_train_pd, y_train_pd)\n",
    "catboost_random.fit(x_train_pd, y_train_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78e4f0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:37:32.530596Z",
     "iopub.status.busy": "2024-12-19T14:37:32.530323Z",
     "iopub.status.idle": "2024-12-19T14:37:32.535007Z",
     "shell.execute_reply": "2024-12-19T14:37:32.534180Z"
    },
    "papermill": {
     "duration": 0.036,
     "end_time": "2024-12-19T14:37:32.536900",
     "exception": false,
     "start_time": "2024-12-19T14:37:32.500900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM Params: {'num_leaves': 478, 'n_estimators': 200, 'min_data_in_leaf': 14, 'max_depth': 12, 'learning_rate': 0.04, 'lambda_l2': 0.01, 'lambda_l1': 12, 'feature_fraction': 0.893, 'bagging_freq': 5, 'bagging_fraction': 0.79}\n",
      "Best LightGBM Score: nan\n",
      "Best XGBoost Params: {'subsample': 0.85, 'reg_lambda': 5, 'reg_alpha': 1.2, 'random_state': 42, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.045, 'colsample_bytree': 0.8}\n",
      "Best XGBoost Score: nan\n",
      "Best CatBoost Params: {'verbose': 0, 'random_seed': 42, 'learning_rate': 0.045, 'l2_leaf_reg': 10, 'iterations': 150, 'depth': 6}\n",
      "Best CatBoost Score: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LightGBM Params:\", lgbm_random.best_params_)\n",
    "print(\"Best LightGBM Score:\", lgbm_random.best_score_)\n",
    "\n",
    "print(\"Best XGBoost Params:\", xgb_random.best_params_)\n",
    "print(\"Best XGBoost Score:\", xgb_random.best_score_)\n",
    "\n",
    "print(\"Best CatBoost Params:\", catboost_random.best_params_)\n",
    "print(\"Best CatBoost Score:\", catboost_random.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882abd9",
   "metadata": {
    "papermill": {
     "duration": 0.028445,
     "end_time": "2024-12-19T14:37:32.593941",
     "exception": false,
     "start_time": "2024-12-19T14:37:32.565496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130f775a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:37:32.652339Z",
     "iopub.status.busy": "2024-12-19T14:37:32.651652Z",
     "iopub.status.idle": "2024-12-19T14:37:32.662912Z",
     "shell.execute_reply": "2024-12-19T14:37:32.662165Z"
    },
    "papermill": {
     "duration": 0.042368,
     "end_time": "2024-12-19T14:37:32.664371",
     "exception": false,
     "start_time": "2024-12-19T14:37:32.622003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def modelTraining(model_class, train_data, test_data):\n",
    "    X = train_data.drop(['sii'], axis=1)\n",
    "    y = train_data['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eee383e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:37:32.721651Z",
     "iopub.status.busy": "2024-12-19T14:37:32.721400Z",
     "iopub.status.idle": "2024-12-19T14:37:32.726259Z",
     "shell.execute_reply": "2024-12-19T14:37:32.725583Z"
    },
    "papermill": {
     "duration": 0.035383,
     "end_time": "2024-12-19T14:37:32.727786",
     "exception": false,
     "start_time": "2024-12-19T14:37:32.692403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Light = LGBMRegressor(**lgbm_random.best_params_, verbose=-1)\n",
    "XGB_Model = XGBRegressor(**xgb_random.best_params_)\n",
    "CatBoost_Model = CatBoostRegressor(**catboost_random.best_params_)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model),\n",
    "    ('catboost', CatBoost_Model)\n",
    "], weights=[4.0, 4.0, 5.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d35c1",
   "metadata": {
    "papermill": {
     "duration": 0.028136,
     "end_time": "2024-12-19T14:37:32.784458",
     "exception": false,
     "start_time": "2024-12-19T14:37:32.756322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model training and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b043efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:37:32.842508Z",
     "iopub.status.busy": "2024-12-19T14:37:32.841879Z",
     "iopub.status.idle": "2024-12-19T14:37:59.441676Z",
     "shell.execute_reply": "2024-12-19T14:37:59.440685Z"
    },
    "papermill": {
     "duration": 26.630656,
     "end_time": "2024-12-19T14:37:59.443445",
     "exception": false,
     "start_time": "2024-12-19T14:37:32.812789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:26<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7718\n",
      "Mean Validation QWK ---> 0.3837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.460\u001b[0m\n",
      "sii\n",
      "0    9\n",
      "1    6\n",
      "2    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "submission = modelTraining(voting_model, train, test)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(submission['sii'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027baf5",
   "metadata": {
    "papermill": {
     "duration": 0.028509,
     "end_time": "2024-12-19T14:37:59.501540",
     "exception": false,
     "start_time": "2024-12-19T14:37:59.473031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 506.095786,
   "end_time": "2024-12-19T14:38:02.863994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-19T14:29:36.768208",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
